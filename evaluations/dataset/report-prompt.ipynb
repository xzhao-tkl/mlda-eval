{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c498028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "ROOT = \"./results\"\n",
    "\n",
    "model_names = [\n",
    "    \"llm-jp-3-13b\",\n",
    "    \"llm-jp-3-13b-exp1\",\n",
    "    \"llm-jp-3-13b-exp1-en\",\n",
    "    \"llm-jp-3-13b-exp3-science\",\n",
    "]\n",
    "\n",
    "templates = [\"standard\", \"english\"]\n",
    "# templates = [\"minimal\"]\n",
    "\n",
    "num_shots = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cedc121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_accs(task2accs):    \n",
    "    prompt_tasks = [\n",
    "        \"nii_en5_mono_prompt-en\",\n",
    "        \"nii_en5_mono_prompt-ja\",\n",
    "        \"nii_en5_bi_prompt-en\",\n",
    "        \"nii_en5_bi_prompt-ja\",\n",
    "        \"nii_en5_tri_prompt-en\",\n",
    "        \"nii_en5_tri_prompt-ja\",\n",
    "        \"nii_ja5_mono_prompt-en\",\n",
    "        \"nii_ja5_mono_prompt-ja\",\n",
    "        \"nii_ja5_bi_prompt-en\",\n",
    "        \"nii_ja5_bi_prompt-ja\",\n",
    "        \"nii_ja5_tri_prompt-en\",\n",
    "        \"nii_ja5_tri_prompt-ja\"]\n",
    "    \n",
    "    for task in prompt_tasks:\n",
    "        print(f\"{task}: {task2accs[task]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f9392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "accs = []\n",
    "for model_name, template, num_shot in itertools.product(model_names, templates, num_shots):\n",
    "    result_dir = os.path.join(ROOT, f\"{model_name}_{template}_{str(num_shot)}-shot\")\n",
    "    if not os.path.exists(result_dir):\n",
    "        print(f\"Directory {result_dir} does not exist.\")\n",
    "        continue\n",
    "    task2accs = {}\n",
    "    csv_file_path = os.path.join(result_dir, f\"prompt.csv\")\n",
    "    if not os.path.isfile(csv_file_path):\n",
    "        print(f\"Task result {csv_file_path} does not exist.\")\n",
    "        continue\n",
    "    # print(f\"Processing task {task} in {result_dir}\")\n",
    "    with open(csv_file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)\n",
    "        for row in reader:\n",
    "            task, acc = row[0], row[3]\n",
    "            task2accs[task] = float(acc)\n",
    "            if (task.endswith(\"ja\") and template == \"english\") or (task.endswith(\"en\") and template == \"standard\"):\n",
    "                continue\n",
    "            # train_lang = \"en\"\n",
    "            if model_name == \"llm-jp-3-13b\":\n",
    "                train_lang = \"none\"\n",
    "            elif model_name == \"llm-jp-3-13b-exp1\":\n",
    "                train_lang = \"ja\"\n",
    "            elif model_name == \"llm-jp-3-13b-exp1-en\":\n",
    "                train_lang = \"en\"\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            accs.append({\n",
    "                \"model_name\": model_name,\n",
    "                \"template-lang\": \"ja\" if template == \"standard\" else \"en\",\n",
    "                # \"template-lang\": \"none\",\n",
    "                \"train-lang\": train_lang,\n",
    "                \"src-eval-lang\": \"ja\" if task.startswith(\"nii_ja\") else \"en\",\n",
    "                \"eval-lang\": \"ja\" if task.endswith(\"ja\") else \"en\",\n",
    "                \"prompt-type\": task.split(\"_\")[2] + \"-sentence\",\n",
    "                # \"num_shot\": num_shot,\n",
    "                \"task\": task,\n",
    "                \"task-prefix\": task.split(\"-\")[0],\n",
    "                \"acc\": round(float(acc), 4),\n",
    "            })\n",
    "    df = pd.DataFrame(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fecfc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang | prompt-type |  acc   |\n",
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "| 7  |    none    |      en       |    en     | bi-sentence | 0.4202 |\n",
      "| 31 |     en     |      en       |    en     | bi-sentence | 0.4267 |\n",
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang |  prompt-type  |  acc   |\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "| 6  |    none    |      en       |    en     | mono-sentence | 0.4785 |\n",
      "| 30 |     en     |      en       |    en     | mono-sentence | 0.4915 |\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "+----+------------+---------------+-----------+--------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang | prompt-type  |  acc   |\n",
      "+----+------------+---------------+-----------+--------------+--------+\n",
      "| 8  |    none    |      en       |    en     | tri-sentence | 0.3917 |\n",
      "| 32 |     en     |      en       |    en     | tri-sentence | 0.3927 |\n",
      "+----+------------+---------------+-----------+--------------+--------+\n",
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang | prompt-type |  acc   |\n",
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "| 4  |    none    |      ja       |    ja     | bi-sentence | 0.4859 |\n",
      "| 16 |     ja     |      ja       |    ja     | bi-sentence | 0.5405 |\n",
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang |  prompt-type  |  acc   |\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "| 3  |    none    |      ja       |    ja     | mono-sentence | 0.4914 |\n",
      "| 15 |     ja     |      ja       |    ja     | mono-sentence | 0.5483 |\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "+----+------------+---------------+-----------+--------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang | prompt-type  |  acc   |\n",
      "+----+------------+---------------+-----------+--------------+--------+\n",
      "| 5  |    none    |      ja       |    ja     | tri-sentence | 0.4504 |\n",
      "| 17 |     ja     |      ja       |    ja     | tri-sentence | 0.4968 |\n",
      "+----+------------+---------------+-----------+--------------+--------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 1. Does the continual-pretraining work well to inject new knowledge? \n",
    "\n",
    "_df = df[(df[\"eval-lang\"]==df[\"train-lang\"]) & (df[\"eval-lang\"]==df[\"src-eval-lang\"]) | (df[\"train-lang\"]== \"none\")]\n",
    "for task, sdf in _df.groupby('task'):\n",
    "    if len(sdf) == 1:\n",
    "        continue\n",
    "    sdf.drop([\"template-lang\", \"model_name\", \"task\", \"task-prefix\"], axis=1, inplace=True)\n",
    "    print(tabulate(sdf, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1aad9f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang | prompt-type |  acc   |\n",
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "| 1  |    none    |      en       |    ja     | bi-sentence | 0.4398 |\n",
      "| 25 |     en     |      en       |    ja     | bi-sentence | 0.4387 |\n",
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang |  prompt-type  |  acc   |\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "| 0  |    none    |      en       |    ja     | mono-sentence | 0.4755 |\n",
      "| 24 |     en     |      en       |    ja     | mono-sentence | 0.4717 |\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "+----+------------+---------------+-----------+--------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang | prompt-type  |  acc   |\n",
      "+----+------------+---------------+-----------+--------------+--------+\n",
      "| 2  |    none    |      en       |    ja     | tri-sentence | 0.4079 |\n",
      "| 26 |     en     |      en       |    ja     | tri-sentence | 0.3969 |\n",
      "+----+------------+---------------+-----------+--------------+--------+\n",
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang | prompt-type |  acc   |\n",
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "| 10 |    none    |      ja       |    en     | bi-sentence | 0.4601 |\n",
      "| 22 |     ja     |      ja       |    en     | bi-sentence | 0.4602 |\n",
      "+----+------------+---------------+-----------+-------------+--------+\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang |  prompt-type  |  acc   |\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "| 9  |    none    |      ja       |    en     | mono-sentence | 0.4857 |\n",
      "| 21 |     ja     |      ja       |    en     | mono-sentence | 0.4861 |\n",
      "+----+------------+---------------+-----------+---------------+--------+\n",
      "+----+------------+---------------+-----------+--------------+--------+\n",
      "|    | train-lang | src-eval-lang | eval-lang | prompt-type  |  acc   |\n",
      "+----+------------+---------------+-----------+--------------+--------+\n",
      "| 11 |    none    |      ja       |    en     | tri-sentence | 0.4364 |\n",
      "| 23 |     ja     |      ja       |    en     | tri-sentence | 0.4354 |\n",
      "+----+------------+---------------+-----------+--------------+--------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## 1. Does the continual-pretraining work well to inject new knowledge? \n",
    "\n",
    "_df = df[(df[\"eval-lang\"]!=df[\"train-lang\"]) & (df[\"train-lang\"]==df[\"src-eval-lang\"]) | (df[\"train-lang\"]== \"none\")]\n",
    "for task, sdf in _df.groupby('task'):\n",
    "    if len(sdf) == 1:\n",
    "        continue\n",
    "    sdf.drop([\"template-lang\", \"model_name\", \"task\", \"task-prefix\"], axis=1, inplace=True)\n",
    "    print(tabulate(sdf, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f1eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-eval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
